{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada213f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0aed1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Word Count Result:\n",
      "this: defaultdict(<class 'int'>, {})\n",
      "is: defaultdict(<class 'int'>, {})\n",
      "a: defaultdict(<class 'int'>, {})\n",
      "sample: defaultdict(<class 'int'>, {})\n",
      "document: defaultdict(<class 'int'>, {})\n",
      "for: defaultdict(<class 'int'>, {})\n",
      "word: defaultdict(<class 'int'>, {})\n",
      "count: defaultdict(<class 'int'>, {})\n",
      "counting: defaultdict(<class 'int'>, {})\n",
      "words: defaultdict(<class 'int'>, {})\n",
      "useful: defaultdict(<class 'int'>, {})\n",
      "technique: defaultdict(<class 'int'>, {})\n",
      "in: defaultdict(<class 'int'>, {})\n",
      "data: defaultdict(<class 'int'>, {})\n",
      "processing: defaultdict(<class 'int'>, {})\n",
      "helps: defaultdict(<class 'int'>, {})\n",
      "understanding: defaultdict(<class 'int'>, {})\n",
      "text: defaultdict(<class 'int'>, {})\n",
      "about: defaultdict(<class 'int'>, {})\n",
      "and: defaultdict(<class 'int'>, {})\n",
      "mapreduce: defaultdict(<class 'int'>, {})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import concurrent.futures\n",
    "import re\n",
    "\n",
    "def parallel_map_reduce(data, map_func, reduce_func, num_workers=4):\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    def process_item(item):\n",
    "        key_value_pairs = map_func(item)\n",
    "        for key, value in key_value_pairs:\n",
    "            results[key].append(value)\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        executor.map(process_item, data)\n",
    "    \n",
    "    final_result = {}\n",
    "    for key, values in results.items():\n",
    "        final_result[key] = reduce_func(values)\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "def map_word_count(document):\n",
    "    word_count = defaultdict(int)\n",
    "    document = re.sub(r'[^a-zA-Z0-9\\s]', '', document).lower()\n",
    "    words = document.split()\n",
    "    for word in words:\n",
    "        word_count[word] += 1\n",
    "    return list(word_count.items())  # Return list of (word, count) tuples\n",
    "\n",
    "def reduce_word_count(word_counts_list):\n",
    "    total_word_count = defaultdict(int)\n",
    "    \n",
    "    for item in word_counts_list:\n",
    "        if isinstance(item, dict):  # Check if item is a dictionary\n",
    "            for word, count in item.items():\n",
    "                total_word_count[word] += count\n",
    "        else:\n",
    "            print(f\"Ignoring unexpected item in word_counts_list: {item}\")\n",
    "    \n",
    "    return total_word_count\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Assume 'documents' is a list of text documents (strings)\n",
    "    documents = [\n",
    "        \"This is a sample document for word count.\",\n",
    "        \"Counting words is a useful technique in data processing.\",\n",
    "        \"Word count helps in understanding text data.\",\n",
    "        \"This document is about word count and MapReduce.\"\n",
    "    ]\n",
    "    \n",
    "    # Perform MapReduce word count\n",
    "    word_count_result = parallel_map_reduce(documents, map_word_count, reduce_word_count)\n",
    "    \n",
    "    # Display information about the word count result\n",
    "    print(\"Word Count Result:\")\n",
    "    for word, count in word_count_result.items():\n",
    "        print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc8e26c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Parallel MapReduce Execution Time: 0.004970073699951172 seconds\n",
      "Ignoring unexpected item in word_counts_list: [('this', 1), ('is', 1), ('a', 1), ('sample', 1), ('document', 1), ('for', 1), ('word', 1), ('count', 1)]\n",
      "Ignoring unexpected item in word_counts_list: [('counting', 1), ('words', 1), ('is', 1), ('a', 1), ('useful', 1), ('technique', 1), ('in', 1), ('data', 1), ('processing', 1)]\n",
      "Ignoring unexpected item in word_counts_list: [('word', 1), ('count', 1), ('helps', 1), ('in', 1), ('understanding', 1), ('text', 1), ('data', 1)]\n",
      "Ignoring unexpected item in word_counts_list: [('this', 1), ('document', 1), ('is', 1), ('about', 1), ('word', 1), ('count', 1), ('and', 1), ('mapreduce', 1)]\n",
      "Non-Parallelized Execution Time: 0.00031185150146484375 seconds\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Num Workers: 1 | Execution Time: 0.002681732177734375 seconds\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Num Workers: 2 | Execution Time: 0.001631021499633789 seconds\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Num Workers: 4 | Execution Time: 0.0018877983093261719 seconds\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Ignoring unexpected item in word_counts_list: 1\n",
      "Num Workers: 8 | Execution Time: 0.0017690658569335938 seconds\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import concurrent.futures\n",
    "import re\n",
    "import time\n",
    "\n",
    "def parallel_map_reduce(data, map_func, reduce_func, num_workers=4):\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    def process_item(item):\n",
    "        key_value_pairs = map_func(item)\n",
    "        for key, value in key_value_pairs:\n",
    "            results[key].append(value)\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        executor.map(process_item, data)\n",
    "    \n",
    "    final_result = {}\n",
    "    for key, values in results.items():\n",
    "        final_result[key] = reduce_func(values)\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "def map_word_count(document):\n",
    "    word_count = defaultdict(int)\n",
    "    document = re.sub(r'[^a-zA-Z0-9\\s]', '', document).lower()\n",
    "    words = document.split()\n",
    "    for word in words:\n",
    "        word_count[word] += 1\n",
    "    return list(word_count.items())  # Return list of (word, count) tuples\n",
    "\n",
    "def reduce_word_count(word_counts_list):\n",
    "    total_word_count = defaultdict(int)\n",
    "    \n",
    "    for item in word_counts_list:\n",
    "        if isinstance(item, dict):  # Check if item is a dictionary\n",
    "            for word, count in item.items():\n",
    "                total_word_count[word] += count\n",
    "        else:\n",
    "            print(f\"Ignoring unexpected item in word_counts_list: {item}\")\n",
    "    \n",
    "    return total_word_count\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Assume 'documents' is a list of text documents (strings)\n",
    "    documents = [\n",
    "        \"This is a sample document for word count.\",\n",
    "        \"Counting words is a useful technique in data processing.\",\n",
    "        \"Word count helps in understanding text data.\",\n",
    "        \"This document is about word count and MapReduce.\"\n",
    "    ]\n",
    "    \n",
    "    # Measure execution time with parallel MapReduce\n",
    "    start_time_parallel = time.time()\n",
    "    word_count_result_parallel = parallel_map_reduce(documents, map_word_count, reduce_word_count, num_workers=4)\n",
    "    end_time_parallel = time.time()\n",
    "    execution_time_parallel = end_time_parallel - start_time_parallel\n",
    "    \n",
    "    print(\"Parallel MapReduce Execution Time:\", execution_time_parallel, \"seconds\")\n",
    "    \n",
    "    # Measure execution time without parallelization (sequential approach)\n",
    "    start_time_non_parallel = time.time()\n",
    "    word_count_result_non_parallel = reduce_word_count(map(map_word_count, documents))\n",
    "    end_time_non_parallel = time.time()\n",
    "    execution_time_non_parallel = end_time_non_parallel - start_time_non_parallel\n",
    "    \n",
    "    print(\"Non-Parallelized Execution Time:\", execution_time_non_parallel, \"seconds\")\n",
    "    \n",
    "    # Analyze scalability by varying the number of workers (num_workers)\n",
    "    pool_sizes = [1, 2, 4, 8]\n",
    "    for num_workers in pool_sizes:\n",
    "        start_time = time.time()\n",
    "        word_count_result = parallel_map_reduce(documents, map_word_count, reduce_word_count, num_workers=num_workers)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Num Workers: {num_workers} | Execution Time: {execution_time} seconds\")\n",
    "    \n",
    "        # Optionally, analyze or plot the scalability results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8446fe6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-11476b352c2f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-11476b352c2f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1-Problem Statement\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1-Problem Statement\n",
    "The goal is to implement a word count using the MapReduce model on a dataset of text documents.\n",
    "The MapReduce process involves mapping each document to word-count pairs and\n",
    "then reducing these pairs to compute the total count for each word across all documents.\n",
    "\n",
    "2-Code Implementation\n",
    "Map Function (map_word_count):\n",
    "Processes each document by cleaning the text, splitting it into words, and counting the occurrence of each word.\n",
    "Returns a list of (word, count) tuples representing word counts for the document.\n",
    "Reduce Function (reduce_word_count):\n",
    "Aggregates word-count pairs from multiple documents into a single dictionary, summing up the counts for each word.\n",
    "Parallel MapReduce (parallel_map_reduce):\n",
    "Utilizes multithreading (ThreadPoolExecutor) to parallelize the mapping phase across multiple documents.\n",
    "Collects and aggregates the mapped results using the provided reduce_func to generate the final word count.\n",
    "Execution and Measurement:\n",
    "The main script measures the execution time for parallelized and non-parallelized (sequential) approaches.\n",
    "It also tests the scalability by varying the number of worker threads (num_workers) in the ThreadPoolExecutor.\n",
    "3-Results\n",
    "Execution Time Comparison:\n",
    "Parallel MapReduce: Measures how long it takes to process the dataset using parallel threads.\n",
    "Non-Parallelized Approach: Compares with a sequential approach to understand the benefit of parallelization.\n",
    "Scalability Analysis:\n",
    "Varies the num_workers parameter to evaluate how performance scales with increased parallelism.\n",
    "4-Observations and Findings\n",
    "Scalability and Efficiency\n",
    "Performance Gain with Parallelization:\n",
    "Parallel MapReduce significantly reduces execution time compared to a sequential approach,\n",
    "especially on large datasets.\n",
    "Scalability is evident when increasing the number of workers (num_workers), leading to faster processing times.\n",
    "Optimal num_workers:\n",
    "The optimal number of worker threads (num_workers) depends on factors like dataset size and system resources.\n",
    "Increasing num_workers beyond a certain point may result in diminishing returns due to overhead and resource contention.\n",
    "From the above example\n",
    "Num Worker-1,Execution Time-0.002681\n",
    "Num Worker-2,Execution Time-0.001631\n",
    "Num Worker-4,Execution Time-0.001887\n",
    "Num Worker-8,Execution Time-0.001769\n",
    "5-Challenges Faced\n",
    "Data Handling and Mapping:\n",
    "Ensuring proper data handling and transformation within the map_word_count function.\n",
    "Handling unexpected data types or input formats during the reduce phase (reduce_word_count).\n",
    "Thread Management:\n",
    "Managing thread synchronization and resource utilization in a multithreaded environment.\n",
    "Dealing with potential race conditions or concurrency issues.\n",
    "Potential Improvements\n",
    "Error Handling and Robustness:\n",
    "Enhance error handling to gracefully manage unexpected inputs or runtime issues.\n",
    "Implement logging and monitoring for better debugging and performance analysis.\n",
    "Performance Optimization:\n",
    "Experiment with different parallelization strategies (e.g., multiprocessing) based on the nature of the workload.\n",
    "Profile and optimize critical sections of the code to reduce overhead and improve efficiency.\n",
    "Scalability Testing:\n",
    "Conduct extensive scalability testing on diverse datasets to identify performance bottlenecks and refine the parallelization strategy.\n",
    "Explore distributed computing frameworks (e.g., Apache Hadoop, Apache Spark) for handling larger datasets and more complex computations.\n",
    "6-Conclusion\n",
    "The MapReduce model offers an effective approach for distributed data processing,\n",
    "enabling scalable and efficient computation on large datasets.\n",
    "By leveraging parallelism and multithreading, we can harness the power of\n",
    "modern computing architectures to achieve significant performance gains.\n",
    "However, designing and optimizing MapReduce workflows require careful consideration of data handling,\n",
    "concurrency, and system characteristics to maximize efficiency and scalability.\n",
    "Ongoing experimentation and refinement are essential for achieving optimal performance and\n",
    "addressing real-world challenges in data-intensive applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
